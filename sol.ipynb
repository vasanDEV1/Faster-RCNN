{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f40cdc-f10e-4e65-b906-60ed537bd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.datasets import CocoDetection\n",
    "from torchvision.transforms import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3710a6aa-935f-40f7-b883-fb78dbeaf14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "class CocoTransform:\n",
    "    def __call__(self, image, target):\n",
    "        image = F.to_tensor(image)  # Convert PIL image to tensor\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de00340b-2882-46c2-8090-a4e4d70c9dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# Dataset class\n",
    "def get_coco_dataset(img_dir, ann_file):\n",
    "    return CocoDetection(\n",
    "        root=img_dir,\n",
    "        annFile=ann_file,\n",
    "        transforms=CocoTransform()\n",
    "    )\n",
    "\n",
    "train_dataset = get_coco_dataset(\n",
    "    img_dir=\"/home/dhvani23/Faster R-CNN/dataset1/train\",\n",
    "    ann_file=\"/home/dhvani23/Faster R-CNN/dataset1/train.json\"\n",
    "\n",
    ")\n",
    "\n",
    "#load the val data\n",
    "val_dataset = get_coco_dataset(\n",
    "    img_dir=\"/home/dhvani23/Faster R-CNN/dataset1/val\",\n",
    "    ann_file=\"/home/dhvani23/Faster R-CNN/dataset1/val.json\"\n",
    ")\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b9f141a-dc16-46cd-b735-38b3241b3062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Faster R-CNN with ResNet-50 backbone\n",
    "def get_model(num_classes):\n",
    "    # Load pre-trained Faster R-CNN\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    \n",
    "    # Get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    \n",
    "    # Replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b8f9e2-e284-490b-9d0c-fe9ef564e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhvani23/miniconda3/envs/psad/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dhvani23/miniconda3/envs/psad/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "num_classes = 2 # Background + chair, human, table\n",
    "model = get_model(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64b71051-288b-455c-85a5-8c8454390488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and learning rate scheduler\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc561163-c6e9-4899-9f4a-a6a8702364f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, data_loader, device, epoch):\n",
    "    model.train()\n",
    "    for images, targets in data_loader:\n",
    "        # Move images to the device\n",
    "        images = [img.to(device) for img in images]\n",
    "\n",
    "        # Validate and process targets\n",
    "        processed_targets = []\n",
    "        valid_images = []\n",
    "        for i, target in enumerate(targets):\n",
    "            boxes = []\n",
    "            labels = []\n",
    "            for obj in target:\n",
    "                # Extract bbox\n",
    "                bbox = obj[\"bbox\"]  # Format: [x, y, width, height]\n",
    "                x, y, w, h = bbox\n",
    "\n",
    "                # Ensure the width and height are positive\n",
    "                if w > 0 and h > 0:\n",
    "                    boxes.append([x, y, x + w, y + h])  # Convert to [x_min, y_min, x_max, y_max]\n",
    "                    labels.append(obj[\"category_id\"])\n",
    "\n",
    "            # Only process if there are valid boxes\n",
    "            if boxes:\n",
    "                processed_target = {\n",
    "                    \"boxes\": torch.tensor(boxes, dtype=torch.float32).to(device),\n",
    "                    \"labels\": torch.tensor(labels, dtype=torch.int64).to(device),\n",
    "                }\n",
    "                processed_targets.append(processed_target)\n",
    "                valid_images.append(images[i])  # Add only valid images\n",
    "\n",
    "        # Skip iteration if no valid targets\n",
    "        if not processed_targets:\n",
    "            continue\n",
    "\n",
    "        # Ensure images and targets are aligned\n",
    "        images = valid_images\n",
    "\n",
    "        # Forward pass\n",
    "        loss_dict = model(images, processed_targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch}] Loss: {losses.item():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f3335f-1e27-472b-aa78-bb8006abab92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0] Loss: 0.0965\n",
      "Model saved: fasterrcnn_resnet50_epoch_1.pth\n",
      "Epoch [1] Loss: 0.0991\n",
      "Epoch [2] Loss: 0.0741\n",
      "Epoch [3] Loss: 0.0441\n",
      "Epoch [4] Loss: 0.0728\n",
      "Epoch [5] Loss: 0.0605\n",
      "Epoch [6] Loss: 0.0674\n",
      "Epoch [7] Loss: 0.0681\n",
      "Epoch [8] Loss: 0.0492\n",
      "Epoch [9] Loss: 0.0552\n",
      "Epoch [10] Loss: 0.0403\n",
      "Model saved: fasterrcnn_resnet50_epoch_11.pth\n",
      "Epoch [11] Loss: 0.0507\n",
      "Epoch [12] Loss: 0.0394\n",
      "Epoch [13] Loss: 0.0427\n",
      "Epoch [14] Loss: 0.0415\n",
      "Epoch [15] Loss: 0.0501\n",
      "Epoch [16] Loss: 0.0512\n",
      "Epoch [17] Loss: 0.0626\n",
      "Epoch [18] Loss: 0.0458\n",
      "Epoch [19] Loss: 0.0446\n",
      "Epoch [20] Loss: 0.0623\n",
      "Model saved: fasterrcnn_resnet50_epoch_21.pth\n",
      "Epoch [21] Loss: 0.0555\n",
      "Epoch [22] Loss: 0.0603\n",
      "Epoch [23] Loss: 0.0471\n",
      "Epoch [24] Loss: 0.0625\n",
      "Epoch [25] Loss: 0.0448\n",
      "Epoch [26] Loss: 0.0660\n",
      "Epoch [27] Loss: 0.0461\n",
      "Epoch [28] Loss: 0.0534\n",
      "Epoch [29] Loss: 0.0511\n",
      "Epoch [30] Loss: 0.0517\n",
      "Model saved: fasterrcnn_resnet50_epoch_31.pth\n",
      "Epoch [31] Loss: 0.0379\n",
      "Epoch [32] Loss: 0.0436\n",
      "Epoch [33] Loss: 0.0525\n",
      "Epoch [34] Loss: 0.0425\n",
      "Epoch [35] Loss: 0.0461\n",
      "Epoch [36] Loss: 0.0420\n",
      "Epoch [37] Loss: 0.0515\n",
      "Epoch [38] Loss: 0.0505\n",
      "Epoch [39] Loss: 0.0869\n",
      "Epoch [40] Loss: 0.0459\n",
      "Model saved: fasterrcnn_resnet50_epoch_41.pth\n",
      "Epoch [41] Loss: 0.0373\n",
      "Epoch [42] Loss: 0.0467\n",
      "Epoch [43] Loss: 0.0406\n",
      "Epoch [44] Loss: 0.0515\n",
      "Epoch [45] Loss: 0.0742\n",
      "Epoch [46] Loss: 0.0737\n",
      "Epoch [47] Loss: 0.0690\n",
      "Epoch [48] Loss: 0.0427\n",
      "Epoch [49] Loss: 0.0407\n",
      "Epoch [50] Loss: 0.0580\n",
      "Model saved: fasterrcnn_resnet50_epoch_51.pth\n",
      "Epoch [51] Loss: 0.0359\n",
      "Epoch [52] Loss: 0.0505\n",
      "Epoch [53] Loss: 0.0416\n",
      "Epoch [54] Loss: 0.0526\n",
      "Epoch [55] Loss: 0.0515\n",
      "Epoch [56] Loss: 0.0565\n",
      "Epoch [57] Loss: 0.0374\n",
      "Epoch [58] Loss: 0.0434\n",
      "Epoch [59] Loss: 0.0453\n",
      "Epoch [60] Loss: 0.0433\n",
      "Model saved: fasterrcnn_resnet50_epoch_61.pth\n",
      "Epoch [61] Loss: 0.0815\n",
      "Epoch [62] Loss: 0.0665\n",
      "Epoch [63] Loss: 0.0615\n",
      "Epoch [64] Loss: 0.0456\n",
      "Epoch [65] Loss: 0.0563\n",
      "Epoch [66] Loss: 0.0585\n",
      "Epoch [67] Loss: 0.0586\n",
      "Epoch [68] Loss: 0.0568\n",
      "Epoch [69] Loss: 0.0447\n",
      "Epoch [70] Loss: 0.0601\n",
      "Model saved: fasterrcnn_resnet50_epoch_71.pth\n",
      "Epoch [71] Loss: 0.0462\n",
      "Epoch [72] Loss: 0.0379\n",
      "Epoch [73] Loss: 0.0558\n",
      "Epoch [74] Loss: 0.0476\n",
      "Epoch [75] Loss: 0.0543\n",
      "Epoch [76] Loss: 0.0456\n",
      "Epoch [77] Loss: 0.0486\n",
      "Epoch [78] Loss: 0.0651\n",
      "Epoch [79] Loss: 0.0453\n",
      "Epoch [80] Loss: 0.0648\n",
      "Model saved: fasterrcnn_resnet50_epoch_81.pth\n",
      "Epoch [81] Loss: 0.0503\n",
      "Epoch [82] Loss: 0.0470\n",
      "Epoch [83] Loss: 0.0516\n",
      "Epoch [84] Loss: 0.0436\n",
      "Epoch [85] Loss: 0.0583\n",
      "Epoch [86] Loss: 0.0537\n",
      "Epoch [87] Loss: 0.0517\n",
      "Epoch [88] Loss: 0.0441\n",
      "Epoch [89] Loss: 0.0386\n",
      "Epoch [90] Loss: 0.0423\n",
      "Model saved: fasterrcnn_resnet50_epoch_91.pth\n",
      "Epoch [91] Loss: 0.0489\n",
      "Epoch [92] Loss: 0.0568\n",
      "Epoch [93] Loss: 0.0398\n",
      "Epoch [94] Loss: 0.0384\n",
      "Epoch [95] Loss: 0.0384\n",
      "Epoch [96] Loss: 0.0517\n",
      "Epoch [97] Loss: 0.0612\n",
      "Epoch [98] Loss: 0.0631\n",
      "Epoch [99] Loss: 0.0670\n",
      "Epoch [100] Loss: 0.0529\n",
      "Model saved: fasterrcnn_resnet50_epoch_101.pth\n",
      "Epoch [101] Loss: 0.0543\n",
      "Epoch [102] Loss: 0.0440\n",
      "Epoch [103] Loss: 0.0361\n",
      "Epoch [104] Loss: 0.0406\n",
      "Epoch [105] Loss: 0.0433\n",
      "Epoch [106] Loss: 0.0498\n",
      "Epoch [107] Loss: 0.0535\n",
      "Epoch [108] Loss: 0.0547\n",
      "Epoch [109] Loss: 0.0324\n",
      "Epoch [110] Loss: 0.0730\n",
      "Model saved: fasterrcnn_resnet50_epoch_111.pth\n",
      "Epoch [111] Loss: 0.0613\n",
      "Epoch [112] Loss: 0.0561\n",
      "Epoch [113] Loss: 0.0370\n",
      "Epoch [114] Loss: 0.0393\n",
      "Epoch [115] Loss: 0.0485\n",
      "Epoch [116] Loss: 0.0396\n",
      "Epoch [117] Loss: 0.0451\n",
      "Epoch [118] Loss: 0.0529\n",
      "Epoch [119] Loss: 0.0436\n",
      "Epoch [120] Loss: 0.0447\n",
      "Model saved: fasterrcnn_resnet50_epoch_121.pth\n",
      "Epoch [121] Loss: 0.0554\n",
      "Epoch [122] Loss: 0.0467\n",
      "Epoch [123] Loss: 0.0450\n",
      "Epoch [124] Loss: 0.0592\n",
      "Epoch [125] Loss: 0.0540\n",
      "Epoch [126] Loss: 0.0483\n",
      "Epoch [127] Loss: 0.0631\n",
      "Epoch [128] Loss: 0.0488\n",
      "Epoch [129] Loss: 0.0291\n",
      "Epoch [130] Loss: 0.0362\n",
      "Model saved: fasterrcnn_resnet50_epoch_131.pth\n",
      "Epoch [131] Loss: 0.0511\n",
      "Epoch [132] Loss: 0.0627\n",
      "Epoch [133] Loss: 0.0511\n",
      "Epoch [134] Loss: 0.0407\n",
      "Epoch [135] Loss: 0.0530\n",
      "Epoch [136] Loss: 0.0558\n",
      "Epoch [137] Loss: 0.0367\n",
      "Epoch [138] Loss: 0.0516\n",
      "Epoch [139] Loss: 0.0441\n",
      "Epoch [140] Loss: 0.0330\n",
      "Model saved: fasterrcnn_resnet50_epoch_141.pth\n",
      "Epoch [141] Loss: 0.0428\n",
      "Epoch [142] Loss: 0.0535\n",
      "Epoch [143] Loss: 0.0405\n",
      "Epoch [144] Loss: 0.0705\n",
      "Epoch [145] Loss: 0.0387\n",
      "Epoch [146] Loss: 0.0461\n",
      "Epoch [147] Loss: 0.0680\n",
      "Epoch [148] Loss: 0.0512\n",
      "Epoch [149] Loss: 0.0412\n",
      "Epoch [150] Loss: 0.0648\n",
      "Model saved: fasterrcnn_resnet50_epoch_151.pth\n",
      "Epoch [151] Loss: 0.0490\n",
      "Epoch [152] Loss: 0.0403\n",
      "Epoch [153] Loss: 0.0488\n",
      "Epoch [154] Loss: 0.0438\n",
      "Epoch [155] Loss: 0.0345\n",
      "Epoch [156] Loss: 0.0365\n",
      "Epoch [157] Loss: 0.0568\n",
      "Epoch [158] Loss: 0.0405\n",
      "Epoch [159] Loss: 0.0463\n",
      "Epoch [160] Loss: 0.0492\n",
      "Model saved: fasterrcnn_resnet50_epoch_161.pth\n",
      "Epoch [161] Loss: 0.0472\n",
      "Epoch [162] Loss: 0.0396\n",
      "Epoch [163] Loss: 0.0452\n",
      "Epoch [164] Loss: 0.0617\n",
      "Epoch [165] Loss: 0.0401\n",
      "Epoch [166] Loss: 0.0660\n",
      "Epoch [167] Loss: 0.0645\n",
      "Epoch [168] Loss: 0.0641\n",
      "Epoch [169] Loss: 0.0426\n",
      "Epoch [170] Loss: 0.0482\n",
      "Model saved: fasterrcnn_resnet50_epoch_171.pth\n",
      "Epoch [171] Loss: 0.0611\n",
      "Epoch [172] Loss: 0.0622\n",
      "Epoch [173] Loss: 0.0471\n",
      "Epoch [174] Loss: 0.0400\n",
      "Epoch [175] Loss: 0.0564\n",
      "Epoch [176] Loss: 0.0495\n",
      "Epoch [177] Loss: 0.0609\n",
      "Epoch [178] Loss: 0.0629\n",
      "Epoch [179] Loss: 0.0471\n",
      "Epoch [180] Loss: 0.0384\n",
      "Model saved: fasterrcnn_resnet50_epoch_181.pth\n",
      "Epoch [181] Loss: 0.0600\n",
      "Epoch [182] Loss: 0.0429\n",
      "Epoch [183] Loss: 0.0560\n",
      "Epoch [184] Loss: 0.0398\n",
      "Epoch [185] Loss: 0.0490\n",
      "Epoch [186] Loss: 0.0612\n",
      "Epoch [187] Loss: 0.0422\n",
      "Epoch [188] Loss: 0.0826\n",
      "Epoch [189] Loss: 0.0479\n",
      "Epoch [190] Loss: 0.0432\n",
      "Model saved: fasterrcnn_resnet50_epoch_191.pth\n",
      "Epoch [191] Loss: 0.0732\n",
      "Epoch [192] Loss: 0.0615\n",
      "Epoch [193] Loss: 0.0530\n",
      "Epoch [194] Loss: 0.0415\n",
      "Epoch [195] Loss: 0.0318\n",
      "Epoch [196] Loss: 0.0437\n",
      "Epoch [197] Loss: 0.0479\n",
      "Epoch [198] Loss: 0.0304\n",
      "Epoch [199] Loss: 0.0454\n",
      "Epoch [200] Loss: 0.0477\n",
      "Model saved: fasterrcnn_resnet50_epoch_201.pth\n",
      "Epoch [201] Loss: 0.0516\n",
      "Epoch [202] Loss: 0.0637\n",
      "Epoch [203] Loss: 0.0423\n",
      "Epoch [204] Loss: 0.0555\n",
      "Epoch [205] Loss: 0.0544\n",
      "Epoch [206] Loss: 0.0441\n",
      "Epoch [207] Loss: 0.0508\n",
      "Epoch [208] Loss: 0.0361\n",
      "Epoch [209] Loss: 0.0549\n",
      "Epoch [210] Loss: 0.0479\n",
      "Model saved: fasterrcnn_resnet50_epoch_211.pth\n",
      "Epoch [211] Loss: 0.0353\n",
      "Epoch [212] Loss: 0.0336\n",
      "Epoch [213] Loss: 0.0469\n",
      "Epoch [214] Loss: 0.0364\n",
      "Epoch [215] Loss: 0.0760\n",
      "Epoch [216] Loss: 0.0473\n",
      "Epoch [217] Loss: 0.0570\n",
      "Epoch [218] Loss: 0.0634\n",
      "Epoch [219] Loss: 0.0398\n",
      "Epoch [220] Loss: 0.0701\n",
      "Model saved: fasterrcnn_resnet50_epoch_221.pth\n"
     ]
    }
}
    
